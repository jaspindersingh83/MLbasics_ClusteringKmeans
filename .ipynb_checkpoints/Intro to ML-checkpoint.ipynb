{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Introduction To Machine Learning\n",
    "In data science, we're often trying to understand a process or system using observational data.\n",
    "\n",
    "Here are a few specific examples:\n",
    "\n",
    "How do the properties of a house affect it's market value?\n",
    "How does an applicant's application affect if they get into graduate school or not?\n",
    "These questions are high-level and tough to answer in the abstract. We can start to narrow these questions to the following:\n",
    "\n",
    "How does the size of a house, the number of rooms, its neighborhood crime index, and age affect it's market value?\n",
    "How does an applicant's college GPA and GRE score affect if they get in to graduate school or not?\n",
    "These more specific questions we can start to answer by applying machine learning techniques on past data.\n",
    "\n",
    "In the first problem, we're interested in trying to predict a specific, real valued number -- the market value of a house in dollars. Whenever we're trying to predict a real valued number, the process is called regression.\n",
    "\n",
    "In the second problem, we're interested in trying to predict a binary value -- acceptance or rejection into graduate school. Whenever we're trying to predict a binary value, the process is called classification.\n",
    "\n",
    "In this mission, we'll focus on a specific regression problem.\n",
    "\n",
    "2: Introduction To The Data\n",
    "How do the properties of a car impact it's fuel efficiency?\n",
    "To try to answer this question, we'll work with a dataset containing fuel efficiencies of several cars compiled by Carnegie Mellon University. The dataset is hosted by the University of California Irvine on their machine learning repository. As a side note, the UCI Machine Learning repository contains many small datasets which are useful when getting your hands dirty with machine learning.\n",
    "\n",
    "You'll notice that the Data Folder contains a few different files. We'll be working with auto-mpg.data, which omits the 8 rows containing missing values for fuel efficiency (mpg column). Even though the file's extension is .data, it's encoded as a plain text file and you can open it using any text editor. If you opened auto-mpg.data in a text editor, you'll notice that the values in each line of the file are separated by a variable number of white spaces:\n",
    "\n",
    "Imgur\n",
    "\n",
    "Since the file isn't formatted as a CSV file and instead uses a variable number of white spaces to delimit the columns, you can't use read_csv to read into a DataFrame. You need to instead use the read_table method, setting the delim_whitespace parameter to True so the file is parsed using the whitespace between values:\n",
    "\n",
    "\n",
    "mpg = pd.read_table(\"auto-mpg.data\", delim_whitespace=True)\n",
    "The file doesn't contain the column names unfortunately so you'll have to extract the column names from auto-mpg.names and specify them manually. The column names can be found in the Attribute Information section. Just like auto-mpg.data, auto-mpg.names is a text file that can be opened using a standard text editor.\n",
    "\n",
    "As specified in auto-mpg.names, the dataset contains 7 numerical features that could have an effect on a car's fuel efficiency:\n",
    "\n",
    "cylinders -- the number of cylinders in the engine.\n",
    "displacement -- the displacement of the engine.\n",
    "horsepower -- the horsepower of the engine.\n",
    "weight -- the weight of the car.\n",
    "acceleration -- the acceleration of the car.\n",
    "model year -- the year that car model was released (e.g. 70 corresponds to 1970).\n",
    "origin -- where the car was manufactured (0 if North America, 1 if Europe, 2 if Asia).\n",
    "When reading in auto-mpg.data using the read_table method, you can use the names parameter to specify the list of column names, as a list of strings. Let's now read in the dataset into a DataFrame so we can explore it further.\n",
    "\n",
    "Instructions\n",
    "Read the dataset auto-mpg.data into a DataFrame named cars using the Pandas method read_table.\n",
    "Specify that you want the whitespace between values to be used as the delimiter.\n",
    "Use the column names provided in auto-mpg.names to set the column names for the cars Dataframe.\n",
    "Display the cars DataFrame using a print statement or by checking the variable inspector below the code box.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "columns = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "2\n",
    "cars = pd.read_table(\"auto-mpg.data\", delim_whitespace=True, names=columns)\n",
    "3\n",
    "print(cars.head(5))\n",
    "Output\n",
    "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
    "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
    "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
    "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
    "3  16.0          8         304.0      150.0  3433.0          12.0          70   \n",
    "4  17.0          8         302.0      140.0  3449.0          10.5          70   \n",
    "\n",
    "   origin                   car name  \n",
    "0       1  chevrolet chevelle malibu  \n",
    "1       1          buick skylark 320  \n",
    "2       1         plymouth satellite  \n",
    "3       1              amc rebel sst  \n",
    "4       1                ford torino  \n",
    "Variables\n",
    " cars\n",
    " columns\n",
    "3: Exploratory Data Analysis\n",
    "Using this dataset, we can work on a more narrow problem:\n",
    "\n",
    "How does the number of cylinders, displacement, horsepower, weight, acceleration, and model year affect a car's fuel efficiency?\n",
    "Let's perform some exploratory data analysis for a couple of the columns to see which one correlates best with fuel efficiency.\n",
    "\n",
    "Instructions\n",
    "Create a grid of subplots containing 2 rows and 1 column.\n",
    "Use the DataFrame.plot() method to generate the following charts:\n",
    "Top chart: Scatter plot with the weight column on the x-axis and the mpg column on the y-axis.\n",
    "Bottom chart: Scatter plot with the acceleration column on the x-axis and the mpg column on the y-axis.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "fig = plt.figure()\n",
    "2\n",
    "ax1 = fig.add_subplot(2,1,1)\n",
    "3\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "4\n",
    "cars.plot(\"weight\", \"mpg\", kind='scatter', ax=ax1)\n",
    "5\n",
    "cars.plot(\"acceleration\", \"mpg\", kind='scatter', ax=ax2)\n",
    "6\n",
    "plt.show()\n",
    "Plots\n",
    "\n",
    "Variables\n",
    " ax1\n",
    " cars\n",
    " fig\n",
    " ax2\n",
    "4: Linear Relationship\n",
    "The scatter plots hint that there's a strong negative linear relationship between the weight and mpg columns and a weak, positive linear relationship between the acceleration and mpg columns. Let's now try to quantify the relationship between weight and mpg.\n",
    "\n",
    "A machine learning model is the equation that represents how the input is mapped to the output. Said another way, machine learning is the process of determining the relationship between the independent variable(s) and the dependent variable. In this case, the dependent variable is the fuel efficiency and the independent variables are the other columns in the dataset.\n",
    "\n",
    "In this mission and the next few missions, we'll focus on a family of machine learning models known as linear models. These models take the form of:\n",
    "\n",
    "y=mx+by=mx+b\n",
    "The input is represented as x, transformed using the parameters m (slope) and b (intercept), and the output is represented as y. We expect m to be a negative number since the relationship is a negative linear one.\n",
    "\n",
    "The process of finding the equation that fits the data the best is called fitting. We won't dive into how a model is fit to the data in this mission and will instead focus on interpreting the model. We'll use the Python library scikit-learn library to handle fitting the model to the data.\n",
    "\n",
    "5: Scikit-Learn\n",
    "To fit the model to the data, we'll use the machine learning library scikit-learn. Scikit-learn is the most popular library for working with machine learning models for small to medium sized datasets. Even when working with larger datasets that don't fit in memory, scikit-learn is commonly used to prototype and explore machine learning models on a subset of the larger dataset.\n",
    "\n",
    "Scikit-learn uses an object-oriented style, so each machine learning model must be instantiated before it can be fit to a dataset (similar to creating a figure in Matplotlib before you plot values). We'll be working with the LinearRegression class from sklearn.linear_model:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "To fit a model to the data, we use the conveniently named fit method:\n",
    "\n",
    "\n",
    "lr.fit(inputs, output)\n",
    "where inputs is a matrix with n_samples rows and n_features columns. The output here can be in one of two formats:\n",
    "\n",
    "either an array with n_samples elements, for when you are predicting only one output, or\n",
    "a matrix with n_samples rows and n_outputs columns, for when you are predicting multiple outputs simultaneously.\n",
    "The dataset we're working with contains 398 rows and 9 columns but since we want to only use the weight column, we need to pass in a matrix containing 398 rows and 1 column. The catch, however, is if you just select the weight column and pass that in as the first parameter to the fit method, an error will be returned. This is because scikit-learn will convert Series and Dataframe objects to NumPy objects and the dimensions won't match.\n",
    "\n",
    "You can use the values attribute to see which NumPy object is returned:\n",
    "\n",
    "\n",
    "cars[\"weight\"].values\n",
    "A NumPy array with 398 elements will be returned instead of a matrix containing rows and columns. You can confirm this by using the shape attribute:\n",
    "\n",
    "\n",
    "cars[\"weight\"].values.shape\n",
    "The value (398,), representing 398 rows by 0 columns, will be returned. If you instead use double bracket notation:\n",
    "\n",
    "\n",
    "cars[[\"weight\"]].values\n",
    "you'll get back a NumPy matrix with 398 rows and 1 column.\n",
    "\n",
    "Instructions\n",
    "Import the LinearRegression class from sklearn.linear_model.\n",
    "Instantiate a LinearRegression instance and assign to lr.\n",
    "Use the fit method to fit a linear regression model using the weight column as the input and the mpg column as the output.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "2\n",
    "lr = LinearRegression()\n",
    "3\n",
    "inputs=cars[['weight']]\n",
    "4\n",
    "output=cars['mpg']\n",
    "5\n",
    "lr.fit(inputs,output)\n",
    "Output\n",
    "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "Variables\n",
    " inputs\n",
    " lr\n",
    " LinearRegression\n",
    " cars\n",
    " output\n",
    "6: Making Predictions\n",
    "Now that we have a trained linear regression model, we can use it to make predictions. Recall that this model takes in a weight value, in pounds, and outputs a fuel efficiency value, in miles per gallon. To use a model to make predictions, use the LinearRegression method predict. The predict method has a single required parameter, the n_samples by n_features input matrix and returns the predicted values as a n_samples by 1 matrix (really just a list).\n",
    "\n",
    "You may be wondering why we'd want to make predictions for the data we trained the model on, since we already know the true fuel efficiency values. Making predictions on data used for training is the first step in the testing & evaluation process. If the model can't do a good job of even capturing the structure of the trained data, then we can't expect it to do a good job on data it wasn't trained on. This is known as underfitting, since the model under performs on the data it was fit on.\n",
    "\n",
    "Instructions\n",
    "Use the LinearRegression method predict to make predictions using the values from the weight column.\n",
    "Assign the resulting list of predictions to predictions.\n",
    "Display the first 5 elements in predictions and the first 5 elements in the mpg column to compare the predicted values with the actual values.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "import sklearn\n",
    "2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "3\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "4\n",
    "lr.fit(cars[[\"weight\"]], cars[\"mpg\"])\n",
    "5\n",
    "predictions=lr.predict(cars[[\"weight\"]])\n",
    "6\n",
    "​\n",
    "Variables\n",
    " lr\n",
    " cars\n",
    " predictions\n",
    " LinearRegression\n",
    "7: Plotting The Model\n",
    "We can now plot the actual fuel efficiency values for each car alongside the predicted fuel efficiency values to gain a visual understanding of the model's effectiveness.\n",
    "\n",
    "Instructions\n",
    "On the same subplot:\n",
    "Generate a scatter plot with weight on the x-axis and the mpg column on the y-axis. Specify that you want the dots in the scatter plot to be red.\n",
    "Generate a scatter plot with weight on the x-axis and the predicted values on the y-axis. Specify that you want the dots in the scatter plot to be blue.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "fig,ax=plt.subplots()\n",
    "2\n",
    "​\n",
    "3\n",
    "​\n",
    "4\n",
    "ax.scatter(cars['weight'],cars['mpg'],color='red')\n",
    "5\n",
    "ax.scatter(cars['weight'],predictions,color='blue')\n",
    "Output\n",
    "<matplotlib.collections.PathCollection at 0x7fefe48a44a8>\n",
    "Plots\n",
    "\n",
    "Variables\n",
    " predictions\n",
    " cars\n",
    " ax\n",
    " fig\n",
    "8: Error Metrics\n",
    "The plot from the last step gave us a visual idea of how well the linear regression model performs. To obtain a more quantitative understanding, we can calculate the model's error, or the mismatch between a model's predictions and the actual values.\n",
    "\n",
    "One commonly used error metric for regression is mean squared error, or MSE for short. You calculate MSE by computing the squared error between each predicted value and the actual value:\n",
    "\n",
    "(Yi^−Yi)2(Yi^−Yi)2\n",
    "where Yi^Yi^ is a predicted value for fuel efficiency and YiYi is the actual mpg value. Then, you compute the mean of all of the squared errors:\n",
    "\n",
    "MSE=1n∑ni=1(Yi^−Yi)2MSE=1n∑i=1n(Yi^−Yi)2\n",
    "Here's the same formula in psuedo-code:\n",
    "\n",
    "\n",
    "sum = 0\n",
    "for each data point:\n",
    "    diff =  predicted_value - actual_value\n",
    "    squared_diff = diff ** 2\n",
    "    sum += squared_diff\n",
    "mse = sum/n\n",
    "We'll use the mean_squared_error function from scikit-learn to calculate MSE. We'll leave it to you to import the function and understand how to use it, so that you become more accustomed to reading documentation.\n",
    "\n",
    "Instructions\n",
    "Import the mean_squared_error function.\n",
    "Use the mean_squared_error function to calculate the MSE of the predicted values and assign to mse.\n",
    "Display the MSE value using a print statement or the variables display below the code cell after you run your code.\n",
    " Need a hint?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script.py\n",
    "console\n",
    "\n",
    "1\n",
    "lr = LinearRegression()\n",
    "2\n",
    "lr.fit(cars[[\"weight\"]], cars[\"mpg\"])\n",
    "3\n",
    "predictions = lr.predict(cars[[\"weight\"]])\n",
    "4\n",
    "from sklearn.metrics import mean_squared_error\n",
    "5\n",
    "mse=mean_squared_error(cars['mpg'],predictions)\n",
    "6\n",
    "print(mse)\n",
    "Output\n",
    "18.7809397346\n",
    "Variables\n",
    " predictions\n",
    " LinearRegression\n",
    " mse\n",
    " cars\n",
    " lr\n",
    "9: Root Mean Squared Error\n",
    "There are many error metrics you can use, each with it's own advantages and disadvantages. While the specific properties of each of the different error metrics is outside the scope of this mission, we'll introduce another error metric here.\n",
    "\n",
    "Root mean squared error, or RMSE for short, is the square root of the MSE and does a better job of penalizing large error values. In addition, the RMSE is easier to interpret since it's units are in the same dimension as the data. When computing MSE, we squared both the predicted and actual values, calculated the differences, then summed all of the differences. This means that the MSE value will be in miles per gallon squared while the RMSE value will be in miles per gallon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
